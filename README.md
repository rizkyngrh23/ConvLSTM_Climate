# Drought Prediction using Deep Learning (Thesis Scripts)

This repository contains the Python scripts used for the undergraduate thesis research:
**"Konstruksi Model Prediksi Kekeringan Menggunakan Convolutional Long-Short Term Memory (ConvLSTM)"**

* **Author:** Rizky Nugraha Putra Herlambang (G2401201080)
* **Institution:** IPB University

The primary goal of this codebase is to preprocess climate model data (NMME hindcasts) and observation data (CHIRPS), train a deep learning model to find a statistical relationship between them, and evaluate the model's performance in predicting the *Standardized Precipitation Index* (SPI).

---

## Workflow Pipeline

The scripts are designed to be run in a specific sequence to process data from its raw form to the final evaluation metrics.

1.  **`lead_accumulation.py`**: Aggregates (averages) raw NMME hindcast data along the 'S' (sample) dimension to create monthly 3D files (Lead, Y, X).
2.  **`fill_missing_data.py`**: (Optional) Fills missing (NaN) values in the accumulated data from the previous step using Inverse Distance Weighting (IDW) interpolation.
3.  **`regrid_with_IDW.py`**: Performs spatial regridding on the model data using IDW to match the high-resolution (0.05°) observation grid.
4.  **`convlstm_training.py`**: The core training script. It loads the regridded model data (Precipitation + SST) and observation data (CHIRPS), trains a CNN model using K-Folds Cross-Validation (K=20), and saves the resulting precipitation predictions.
5.  **`spi_calculation.py`**: Converts the raw precipitation predictions from the trained model into *Standardized Precipitation Index* (SPI) values using a Gamma distribution fit.
6.  **`ROC_AUC_Analysis.py`**: The final evaluation script. It compares the predicted SPI against the observed SPI to generate probabilistic performance metrics, including ROC curves and AUC scores.

---

## Script Descriptions

Here is a detailed breakdown of each Python script included in this repository.

### 1. `lead_accumulation.py`

* **Purpose**: Pre-processes raw NMME hindcast data.
* **Function**: Reads raw NetCDF files for each model (CanSIPSv2, CanCM4i, IC3, NEMO) and each *issued time* (Nov-Mar).
* **Process**: Averages the data along the `S` (sample) dimension to create an aggregated 3D file (Lead, Y, X). This simplifies the data structure for further processing.
* **Output**: Aggregated NetCDF files (e.g., `acc_nov_cancm.nc`, `acc_nino_nov_cancm.nc`).

### 2. `fill_missing_data.py`

* **Purpose**: Fills missing (NaN) data points in the accumulated NetCDF files.
* **Function**: Iterates through the output files from `lead_accumulation.py`.
* **Process**: Applies an Inverse Distance Weighting (IDW) interpolation across the spatial domain (X, Y) for each time step (T) to fill NaNs.
* **Output**: New NetCDF files prefixed with `filled_` (e.g., `filled_acc_nov_cancm.nc`).

### 3. `regrid_with_IDW.py`

* **Purpose**: Standardizes the spatial resolution of model data to match the observation grid.
* **Function**: Reads the accumulated/filled NetCDF files.
* **Process**: Uses IDW interpolation to upsample the grid resolution (e.g., from 1° to 0.05°) for each lead time (L), matching the CHIRPS data resolution.
* **Output**: High-resolution NetCDF files (e.g., `regrid_nov_cancm.nc`).

### 4. `convlstm_training.py`

* **Purpose**: The main model training script.
* **Note on Naming**: While the file is named `convlstm_training.py` (matching the thesis title), the architecture implemented in the `create_cnn_model` function is a **standard Convolutional Neural Network (CNN)**, *not* a ConvLSTM. The model uses `Conv2D`, `MaxPooling2D`, and `Dense` layers.
* **Process**:
    1.  Loads the regridded predictor data (Precipitation and SST) and the observation data (CHIRPS).
    2.  Normalizes all data.
    3.  Builds the CNN model using Keras (TensorFlow).
    4.  Trains the model using **K-Folds Cross-Validation** (K=20).
    5.  Applies `EarlyStopping` and `L2` regularization to prevent overfitting.
    6.  Evaluates the best model from the folds and saves its final precipitation predictions.
* **Output**: NetCDF prediction files (e.g., `predictions_model_cancm_dec.nc`) and learning curve plots.

### 5. `spi_calculation.py`

* **Purpose**: Converts precipitation predictions into a standardized drought index (SPI).
* **Function**: Reads the raw prediction files generated by `convlstm_training.py`.
* **Process**: Calculates SPI by fitting the precipitation data to a **Gamma distribution** and then transforming the cumulative probability to a normal distribution.
* **Output**: NetCDF files containing SPI values (e.g., `spi_dec_model_cancm_dec.nc`).

### 6. `ROC_AUC_Analysis.py`

* **Purpose**: Provides a comprehensive probabilistic evaluation of the model's performance.
* **Function**: Compares the predicted SPI (from `spi_calculation.py`) with the observed SPI.
* **Process**:
    1.  Calculates **binary** (drought vs. non-drought) and **multi-class** (e.g., Extreme Drought, Mild Drought) ROC curves and AUC scores.
    2.  Generates comprehensive 2x2 and 5x4 grid plots visualizing performance across all models and issued months.
    3.  Includes functionality for spatial (per-grid) ROC analysis (requires `cartopy` and a shapefile).
* **Output**: Various `.png` plots (e.g., `roc_grid_drought_classes.png`) and a text-based summary of results (`roc_auc_consolidated_results.txt`).

---

## Requirements

This project relies on the Python scientific stack. Key libraries include:

* `numpy`
* `xarray`
* `scipy`
* `tensorflow` (and `keras`)
* `matplotlib`
* `scikit-learn`
* `geopandas` (for `ROC_AUC_Analysis.py`)
* `cartopy` (optional, for spatial plots in `ROC_AUC_Analysis.py`)
* `tqdm`

---

## Usage Notes

* **Hardcoded Paths**: All scripts in this repository contain hardcoded absolute paths (e.g., `D:/Kuliah/Skripsi/Data_baru/...`). To run this code, you must modify all file and directory paths in each script to match your local environment.
* **Execution Order**: The scripts are not self-contained and must be run in the order specified in the **Workflow Pipeline** section, as the output of one script serves as the input for the next.

---

## How to Cite

If you use this code or reference this work in your research, please cite the original thesis:

> Herlambang, R. N. P. (2025). *Konstruksi Model Prediksi Kekeringan Menggunakan Convolutional Long-Short Term Memory (ConvLSTM)*. [Unpublished undergraduate thesis]. IPB University, Bogor, Indonesia.
